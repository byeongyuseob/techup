#!/bin/bash

# ì™„ì „ ìë™í™” ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ëª¨ë“  í™˜ê²½ì´ ìë™ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

set -e

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# í¬íŠ¸ ì„¤ì • íŒŒì¼ ë¡œë“œ
source ./ports.conf

echo -e "${BLUE}================================================${NC}"
echo -e "${BLUE}     ì™„ì „ ìë™í™” ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘${NC}"
echo -e "${BLUE}================================================${NC}"

# 1. ê¸°ì¡´ í™˜ê²½ ì •ë¦¬
echo -e "\n${YELLOW}[1/10] ê¸°ì¡´ í™˜ê²½ ì •ë¦¬ ì¤‘...${NC}"
docker compose down 2>/dev/null || true
pkill -f auto-scaler.sh 2>/dev/null || true
pkill -f alert-webhook.py 2>/dev/null || true
pkill -f docker-stats-exporter.py 2>/dev/null || true
sleep 2

# 2. í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
echo -e "\n${YELLOW}[2/10] í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...${NC}"
mkdir -p prometheus
mkdir -p alertmanager
mkdir -p haproxy
mkdir -p nginx
mkdir -p grafana/provisioning/dashboards
mkdir -p grafana/provisioning/datasources
mkdir -p grafana/dashboards

# 3. docker-compose.yml ìƒì„±
echo -e "\n${YELLOW}[3/10] Docker Compose íŒŒì¼ ìƒì„± ì¤‘...${NC}"
cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  haproxy:
    image: haproxytech/haproxy-alpine:2.8
    container_name: haproxy
    ports:
      - "${HAPROXY_HTTP_PORT}:80"
      - "${HAPROXY_STATS_PORT}:8404"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - nfs-shared:/mnt/nfs:rw
    networks:
      - load-balancer-net
    depends_on:
      - nginx
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/index.html:/usr/share/nginx/html/index.html:ro
      - nfs-shared:/mnt/nfs:rw
    expose:
      - "${NGINX_PORT}"
    networks:
      - load-balancer-net
    restart: unless-stopped
    deploy:
      replicas: ${INITIAL_INSTANCES}

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "${PROMETHEUS_PORT}:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert.rules.yml:/etc/prometheus/alert.rules.yml:ro
      - prometheus_data:/prometheus
    networks:
      - load-balancer-net
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "${NODE_EXPORTER_PORT}:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)'
    networks:
      - load-balancer-net
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "${ALERTMANAGER_PORT}:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    networks:
      - load-balancer-net
    restart: unless-stopped

  nginx-exporter:
    image: nginx/nginx-prometheus-exporter:latest
    container_name: nginx-exporter
    ports:
      - "${NGINX_EXPORTER_PORT}:9113"
    command:
      - --nginx.scrape-uri=http://haproxy/nginx-status
    networks:
      - load-balancer-net
    depends_on:
      - nginx
      - haproxy
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "${GRAFANA_PORT}:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/etc/grafana/dashboards:ro
    networks:
      - load-balancer-net
    restart: unless-stopped

networks:
  load-balancer-net:
    driver: bridge

volumes:
  prometheus_data:
  alertmanager_data:
  grafana_data:
  nfs-shared:
    driver: local
    driver_opts:
      type: nfs
      o: addr=${NFS_SERVER_IP},rw,nolock,hard,intr
      device: ":${NFS_MOUNT_PATH}"
EOF

# docker-compose.ymlì— í¬íŠ¸ ë³€ìˆ˜ ì¹˜í™˜
envsubst < docker-compose.yml > docker-compose.tmp && mv docker-compose.tmp docker-compose.yml

# 4. HAProxy ì„¤ì • ìƒì„±
echo -e "\n${YELLOW}[4/10] HAProxy ì„¤ì • ìƒì„± ì¤‘...${NC}"
cat > haproxy/haproxy.cfg << EOF
global
    log stdout local0
    maxconn 4096
    stats socket /var/run/haproxy.sock mode 660 level admin
    stats timeout 30s

defaults
    log global
    mode http
    option httplog
    option dontlognull
    timeout connect 5000
    timeout client  50000
    timeout server  50000
    stats enable
    stats uri /haproxy-stats
    stats refresh 10s

frontend http_front
    bind *:80
    acl is_stats path_beg /haproxy-stats
    acl is_nginx_status path_beg /nginx-status
    use_backend stats if is_stats
    use_backend nginx_status if is_nginx_status
    default_backend nginx-backend

backend stats
    stats enable
    stats uri /haproxy-stats
    stats refresh 10s
    stats show-legends
    stats show-node

backend nginx_status
    balance roundrobin
    server-template nginx- 1-20 nginx:${NGINX_PORT} check resolvers docker init-addr libc,none

backend nginx-backend
    balance roundrobin
    option httpchk GET /health
    http-check expect status 200
    server-template nginx- 1-20 nginx:${NGINX_PORT} check resolvers docker init-addr libc,none

resolvers docker
    nameserver dns1 127.0.0.11:53
    resolve_retries 3
    timeout resolve 1s
    timeout retry 1s
    hold other 10s
    hold refused 10s
    hold nx 10s
    hold timeout 10s
    hold valid 10s
    hold obsolete 10s

frontend stats
    bind *:8404
    option http-use-htx
    http-request use-service prometheus-exporter if { path /metrics }
    stats enable
    stats uri /stats
    stats refresh 10s
EOF

# 5. Nginx ì„¤ì • ìƒì„±
echo -e "\n${YELLOW}[5/10] Nginx ì„¤ì • ìƒì„± ì¤‘...${NC}"
cat > nginx/nginx.conf << 'EOF'
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    keepalive_timeout 65;

    server {
        listen 8080;
        server_name _;

        location / {
            root /usr/share/nginx/html;
            index index.html;
        }

        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        location /nginx-status {
            stub_status;
            access_log off;
        }
    }
}
EOF

cat > nginx/index.html << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>Nginx Load Balancing Demo</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 50px; }
        .container { max-width: 800px; margin: 0 auto; }
        h1 { color: #333; }
        .info { background: #f0f0f0; padding: 20px; border-radius: 5px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Nginx Auto-Scaling Demo</h1>
        <div class="info">
            <p><strong>Container Hostname:</strong> <span id="hostname"></span></p>
            <p><strong>Container IP:</strong> <span id="ip"></span></p>
            <p><strong>Current Time:</strong> <span id="time"></span></p>
        </div>
    </div>
    <script>
        document.getElementById('hostname').innerText = location.hostname;
        document.getElementById('time').innerText = new Date().toLocaleString();
    </script>
</body>
</html>
EOF

# 6. Prometheus ì„¤ì • ìƒì„±
echo -e "\n${YELLOW}[6/10] Prometheus ì„¤ì • ìƒì„± ì¤‘...${NC}"
cat > prometheus/prometheus.yml << EOF
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - "alert.rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']

  - job_name: 'haproxy'
    static_configs:
      - targets: ['haproxy:8404']

  - job_name: 'docker-stats'
    static_configs:
      - targets: ['host.docker.internal:${DOCKER_STATS_PORT}']

  - job_name: 'alertmanager'
    static_configs:
      - targets: ['alertmanager:9093']
EOF

cat > prometheus/alert.rules.yml << EOF
groups:
  - name: auto-scaling
    interval: 10s
    rules:
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[1m]) * 100 > ${CPU_THRESHOLD_UP}
        for: 30s
        labels:
          severity: warning
          action: scale_up
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above ${CPU_THRESHOLD_UP}% for more than 30 seconds"

      - alert: LowCPUUsage
        expr: rate(container_cpu_usage_seconds_total[1m]) * 100 < ${CPU_THRESHOLD_DOWN}
        for: 1m
        labels:
          severity: info
          action: scale_down
        annotations:
          summary: "Low CPU usage detected"
          description: "CPU usage is below ${CPU_THRESHOLD_DOWN}% for more than 1 minute"

      - alert: NginxHighConnectionCount
        expr: nginx_connections_active > 10
        for: 30s
        labels:
          severity: warning
        annotations:
          summary: "High number of active connections"
          description: "Nginx has more than 10 active connections"

      - alert: NginxDown
        expr: up{job="nginx"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Nginx exporter is down"
          description: "Nginx exporter has been down for more than 30 seconds"

      - alert: AutoScalingTriggered
        expr: changes(nginx_up[5m]) > 0
        labels:
          severity: info
        annotations:
          summary: "Auto-scaling event detected"
          description: "Number of Nginx instances has changed"
EOF

# 7. AlertManager ì„¤ì • ìƒì„±
echo -e "\n${YELLOW}[7/10] AlertManager ì„¤ì • ìƒì„± ì¤‘...${NC}"
cat > alertmanager/alertmanager.yml << EOF
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'webhook-receiver'

receivers:
  - name: 'webhook-receiver'
    webhook_configs:
      - url: 'http://host.docker.internal:${ALERT_WEBHOOK_PORT}/alert'
        send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
EOF

# 8. Grafana ì„¤ì • ìƒì„±
echo -e "\n${YELLOW}[8/10] Grafana ì„¤ì • ìƒì„± ì¤‘...${NC}"
cat > grafana/provisioning/datasources/prometheus.yml << EOF
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
EOF

cat > grafana/provisioning/dashboards/dashboard.yml << EOF
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    options:
      path: /etc/grafana/dashboards
EOF

cat > grafana/dashboards/unified-dashboard.json << 'EOF'
{
  "dashboard": {
    "id": null,
    "uid": "unified-dashboard",
    "title": "í†µí•© ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
    "panels": [
      {
        "id": 1,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "type": "graph",
        "title": "Nginx í™œì„± ì—°ê²° ìˆ˜",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "nginx_connections_active",
            "refId": "A"
          }
        ]
      },
      {
        "id": 2,
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "type": "graph",
        "title": "CPU ì‚¬ìš©ë¥ ",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total[1m]) * 100",
            "refId": "A"
          }
        ]
      },
      {
        "id": 3,
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
        "type": "alert-list",
        "title": "í™œì„± ì•ŒëŒ",
        "options": {
          "showOptions": "current",
          "maxItems": 10,
          "sortOrder": 1,
          "dashboardAlerts": false,
          "alertName": "",
          "dashboardTitle": "",
          "tags": []
        }
      }
    ],
    "time": {"from": "now-1h", "to": "now"},
    "timepicker": {},
    "timezone": "",
    "schemaVersion": 27,
    "version": 0
  }
}
EOF

# 9. ì§€ì› ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
echo -e "\n${YELLOW}[9/10] ì§€ì› ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...${NC}"

# Auto-scaler ìŠ¤í¬ë¦½íŠ¸
cat > auto-scaler.sh << 'EOF'
#!/bin/bash

source ./ports.conf

# ìƒ‰ìƒ ì •ì˜
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

echo -e "${GREEN}[Auto-Scaler] ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ ì‹œì‘${NC}"
echo -e "${GREEN}[Auto-Scaler] ì„¤ì •: MIN=$MIN_INSTANCES, MAX=$MAX_INSTANCES${NC}"
echo -e "${GREEN}[Auto-Scaler] CPU: UP>$CPU_THRESHOLD_UP%, DOWN<$CPU_THRESHOLD_DOWN%${NC}"
echo -e "${GREEN}[Auto-Scaler] ìš”ì²­: UP>$REQ_THRESHOLD_UP/s, DOWN<$REQ_THRESHOLD_DOWN/s${NC}"

while true; do
    # í˜„ì¬ Nginx ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
    current_instances=$(docker ps --filter "name=nginx" --format "{{.Names}}" | wc -l)

    # CPU ì‚¬ìš©ë¥  í™•ì¸ (Prometheusì—ì„œ)
    cpu_usage=$(curl -s "http://localhost:9090/api/v1/query?query=avg(rate(container_cpu_usage_seconds_total[1m]))*100" | \
                grep -o '"value":\[[0-9.]*,"[0-9.]*"' | \
                sed 's/.*,"\([0-9.]*\)".*/\1/' | \
                cut -d. -f1)

    # ìš”ì²­ ì†ë„ í™•ì¸ (HAProxy ë©”íŠ¸ë¦­)
    req_rate=$(curl -s "http://localhost:8404/metrics" | \
               grep "haproxy_backend_http_requests_total" | \
               grep "nginx-backend" | \
               awk '{print $2}' | \
               head -1)

    # ê¸°ë³¸ê°’ ì„¤ì •
    cpu_usage=${cpu_usage:-0}
    req_rate=${req_rate:-0}

    echo -e "${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')] í˜„ì¬ ìƒíƒœ: ì¸ìŠ¤í„´ìŠ¤=$current_instances, CPU=$cpu_usage%, ìš”ì²­=$req_rate/s${NC}"

    # ìŠ¤ì¼€ì¼ ì—… ì¡°ê±´
    if [[ $current_instances -lt $MAX_INSTANCES ]] && \
       ([[ $cpu_usage -gt $CPU_THRESHOLD_UP ]] || [[ ${req_rate%.*} -gt $REQ_THRESHOLD_UP ]]); then
        new_instances=$((current_instances + 1))
        echo -e "${RED}[Auto-Scaler] ìŠ¤ì¼€ì¼ ì—…: $current_instances â†’ $new_instances${NC}"
        docker compose up -d --scale nginx=$new_instances --no-recreate
        sleep 10  # ì•ˆì •í™” ëŒ€ê¸°

    # ìŠ¤ì¼€ì¼ ë‹¤ìš´ ì¡°ê±´
    elif [[ $current_instances -gt $MIN_INSTANCES ]] && \
         [[ $cpu_usage -lt $CPU_THRESHOLD_DOWN ]] && \
         [[ ${req_rate%.*} -lt $REQ_THRESHOLD_DOWN ]]; then
        new_instances=$((current_instances - 1))
        echo -e "${GREEN}[Auto-Scaler] ìŠ¤ì¼€ì¼ ë‹¤ìš´: $current_instances â†’ $new_instances${NC}"
        docker compose up -d --scale nginx=$new_instances --no-recreate
        sleep 10  # ì•ˆì •í™” ëŒ€ê¸°
    fi

    sleep $CHECK_INTERVAL
done
EOF
chmod +x auto-scaler.sh

# Alert webhook ìŠ¤í¬ë¦½íŠ¸
cat > alert-webhook.py << 'EOF'
#!/usr/bin/env python3
from flask import Flask, request, jsonify
from datetime import datetime
import json

app = Flask(__name__)

@app.route('/alert', methods=['POST'])
def receive_alert():
    try:
        data = request.json
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        for alert in data.get('alerts', []):
            status = alert.get('status', 'unknown')
            alert_name = alert.get('labels', {}).get('alertname', 'unknown')
            severity = alert.get('labels', {}).get('severity', 'unknown')
            description = alert.get('annotations', {}).get('description', 'No description')

            # ìƒ‰ìƒ ì½”ë“œ
            color = '\033[0;32m' if status == 'resolved' else '\033[0;31m'
            nc = '\033[0m'

            print(f"{color}[{timestamp}] Alert: {alert_name}{nc}")
            print(f"  Status: {status}")
            print(f"  Severity: {severity}")
            print(f"  Description: {description}")
            print("-" * 50)

        return jsonify({"status": "success"}), 200
    except Exception as e:
        print(f"Error processing alert: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == '__main__':
    print("Alert Webhook Server started on port 8082")
    app.run(host='0.0.0.0', port=8082)
EOF
chmod +x alert-webhook.py

# Docker stats exporter
cat > docker-stats-exporter.py << 'EOF'
#!/usr/bin/env python3
import json
import time
import subprocess
from http.server import HTTPServer, BaseHTTPRequestHandler

class MetricsHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path == '/metrics':
            try:
                result = subprocess.run(
                    ['docker', 'stats', '--no-stream', '--format', 'json'],
                    capture_output=True,
                    text=True
                )

                metrics = []
                for line in result.stdout.strip().split('\n'):
                    if line:
                        data = json.loads(line)
                        container = data['Name'].replace('-', '_')
                        cpu = data['CPUPerc'].replace('%', '')
                        mem = data['MemUsage'].split('/')[0]

                        metrics.append(f'docker_cpu_percent{{container="{container}"}} {cpu}')
                        metrics.append(f'docker_memory_usage{{container="{container}"}} {len(mem)}')

                response = '\n'.join(metrics)
                self.send_response(200)
                self.send_header('Content-Type', 'text/plain')
                self.end_headers()
                self.wfile.write(response.encode())
            except Exception as e:
                self.send_response(500)
                self.end_headers()
                self.wfile.write(str(e).encode())
        else:
            self.send_response(404)
            self.end_headers()

    def log_message(self, format, *args):
        return  # Suppress logs

if __name__ == '__main__':
    server = HTTPServer(('0.0.0.0', 8081), MetricsHandler)
    print('Docker Stats Exporter started on port 8081')
    server.serve_forever()
EOF
chmod +x docker-stats-exporter.py

# ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
cat > start.sh << 'EOF'
#!/bin/bash

source ./ports.conf

echo "ğŸ§¹ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬..."
docker compose down

echo ""
echo "ğŸš€ Docker Compose ì‹œì‘ (nginx ${INITIAL_INSTANCES}ê°œ ì¸ìŠ¤í„´ìŠ¤)"
docker compose up -d --scale nginx=${INITIAL_INSTANCES}

echo ""
echo "â³ ì„œë¹„ìŠ¤ ì•ˆì •í™” ëŒ€ê¸° (10ì´ˆ)..."
sleep 10

echo ""
echo "âœ… í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ nginx ì¸ìŠ¤í„´ìŠ¤:"
docker ps --format "table {{.Names}}\t{{.Status}}" | grep -E "NAME|nginx"

echo ""
echo "ğŸ”„ Auto-scaler ì¬ì‹œì‘..."
pkill -f auto-scaler.sh 2>/dev/null
sleep 1
nohup ./auto-scaler.sh > /var/log/auto-scaler.log 2>&1 &
echo "âœ… Auto-scaler ì‹œì‘ë¨ (ë¡œê·¸: /var/log/auto-scaler.log)"

echo ""
echo "==============================================="
echo "ğŸ“Š Auto-scaling ì„¤ì •:"
echo "  - ìµœì†Œ: ${MIN_INSTANCES}ê°œ, ìµœëŒ€: ${MAX_INSTANCES}ê°œ"
echo "  - CPU ì„ê³„ì¹˜: >${CPU_THRESHOLD_UP}% (Scale UP), <${CPU_THRESHOLD_DOWN}% (Scale DOWN)"
echo "  - ì²´í¬ ê°„ê²©: ${CHECK_INTERVAL}ì´ˆ"
echo ""
echo "ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´:"
echo "  docker exec -it workspace-nginx-1 stress -c 1"
echo "  â†’ ì´ ëª…ë ¹ì–´ë§Œìœ¼ë¡œë„ Auto-scaling ë°œìƒ!"
echo ""
echo "ğŸ“ ëª¨ë‹ˆí„°ë§ URL:"
echo "  - HAProxy: http://localhost/haproxy-stats"
echo "  - Grafana: http://localhost:3000"
echo "  - Prometheus: http://localhost:9090"
echo "==============================================="
EOF
chmod +x start.sh

# 10. ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì‹œì‘
echo -e "\n${YELLOW}[10/10] ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘...${NC}"

# Alert webhook ì‹œì‘
nohup python3 alert-webhook.py > /var/log/alert-webhook.log 2>&1 &
echo -e "${GREEN}âœ“ Alert Webhook ì‹œì‘ë¨${NC}"

# Docker stats exporter ì‹œì‘
nohup python3 docker-stats-exporter.py > /var/log/docker-stats-exporter.log 2>&1 &
echo -e "${GREEN}âœ“ Docker Stats Exporter ì‹œì‘ë¨${NC}"

# Docker Compose ì‹œì‘
echo -e "\n${BLUE}Docker Compose ì‹œì‘ ì¤‘...${NC}"
docker compose up -d --scale nginx=${INITIAL_INSTANCES}

# ì„œë¹„ìŠ¤ ì•ˆì •í™” ëŒ€ê¸°
echo -e "\n${YELLOW}ì„œë¹„ìŠ¤ ì•ˆì •í™” ëŒ€ê¸° (15ì´ˆ)...${NC}"
sleep 15

# Auto-scalerëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹œì‘
echo -e "\n${YELLOW}Auto-scalerëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”:${NC}"
echo "  ./auto-scaler.sh &"
echo "  ë˜ëŠ”"
echo "  nohup ./auto-scaler.sh > /var/log/auto-scaler.log 2>&1 &"

# ìƒíƒœ í™•ì¸
echo -e "\n${BLUE}================================================${NC}"
echo -e "${BLUE}                ë°°í¬ ì™„ë£Œ!${NC}"
echo -e "${BLUE}================================================${NC}"

echo -e "\n${GREEN}ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ:${NC}"
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

echo -e "\n${GREEN}ì„œë¹„ìŠ¤ ì ‘ì† ì •ë³´:${NC}"
echo "  - HAProxy Stats: http://localhost:${HAPROXY_HTTP_PORT}/haproxy-stats"
echo "  - Grafana: http://localhost:${GRAFANA_PORT} (admin/admin)"
echo "  - Prometheus: http://localhost:${PROMETHEUS_PORT}"
echo "  - AlertManager: http://localhost:${ALERTMANAGER_PORT}"

echo -e "\n${GREEN}ë¡œê·¸ í™•ì¸:${NC}"
echo "  - Auto-scaler: tail -f /var/log/auto-scaler.log"
echo "  - Alert Webhook: tail -f /var/log/alert-webhook.log"
echo "  - Docker Stats: tail -f /var/log/docker-stats-exporter.log"

# 11. Auto-scaler ìë™ ì‹œì‘
echo -e "\n${YELLOW}[11/12] Auto-scaler ìë™ ì‹œì‘ ì¤‘...${NC}"
nohup ./auto-scaler.sh > /var/log/auto-scaler.log 2>&1 &
echo -e "${GREEN}âœ“ Auto-scaler ì‹œì‘ë¨${NC}"
sleep 5

# 12. ë°°í¬ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo -e "\n${YELLOW}[12/12] ë°°í¬ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...${NC}"

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
TESTS_PASSED=0
TESTS_FAILED=0

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
run_test() {
    local test_name="$1"
    local test_command="$2"

    echo -ne "${YELLOW}[TEST] ${test_name}...${NC} "

    if eval "$test_command" > /dev/null 2>&1; then
        echo -e "${GREEN}âœ“ PASS${NC}"
        ((TESTS_PASSED++))
        return 0
    else
        echo -e "${RED}âœ— FAIL${NC}"
        ((TESTS_FAILED++))
        return 1
    fi
}

echo -e "\n${BLUE}1. ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸${NC}"
run_test "HAProxy ì»¨í…Œì´ë„ˆ" "docker ps | grep -q haproxy"
run_test "Prometheus ì»¨í…Œì´ë„ˆ" "docker ps | grep -q prometheus"
run_test "Grafana ì»¨í…Œì´ë„ˆ" "docker ps | grep -q grafana"
run_test "AlertManager ì»¨í…Œì´ë„ˆ" "docker ps | grep -q alertmanager"
run_test "Node Exporter ì»¨í…Œì´ë„ˆ" "docker ps | grep -q node-exporter"
run_test "Nginx Exporter ì»¨í…Œì´ë„ˆ" "docker ps | grep -q nginx-exporter"
run_test "Nginx ì»¨í…Œì´ë„ˆ (ìµœì†Œ ${MIN_INSTANCES}ê°œ)" "[ $(docker ps --filter 'name=nginx' --format '{{.Names}}' | wc -l) -ge ${MIN_INSTANCES} ]"

echo -e "\n${BLUE}2. ì„œë¹„ìŠ¤ ì ‘ê·¼ì„± í™•ì¸${NC}"
run_test "HAProxy HTTP (í¬íŠ¸ ${HAPROXY_HTTP_PORT})" "curl -s -o /dev/null -w '%{http_code}' http://localhost:${HAPROXY_HTTP_PORT} | grep -q '200'"
run_test "HAProxy Stats (í¬íŠ¸ ${HAPROXY_STATS_PORT})" "curl -s -o /dev/null -w '%{http_code}' http://localhost:${HAPROXY_STATS_PORT}/stats | grep -q '200'"
run_test "Prometheus (í¬íŠ¸ ${PROMETHEUS_PORT})" "curl -s -o /dev/null -w '%{http_code}' http://localhost:${PROMETHEUS_PORT}/-/ready | grep -q '200'"
run_test "Grafana (í¬íŠ¸ ${GRAFANA_PORT})" "curl -s -o /dev/null -w '%{http_code}' http://localhost:${GRAFANA_PORT}/api/health | grep -q '200'"
run_test "AlertManager (í¬íŠ¸ ${ALERTMANAGER_PORT})" "curl -s -o /dev/null -w '%{http_code}' http://localhost:${ALERTMANAGER_PORT}/-/ready | grep -q '200'"

echo -e "\n${BLUE}3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸${NC}"
run_test "Node Exporter ë©”íŠ¸ë¦­" "curl -s http://localhost:${NODE_EXPORTER_PORT}/metrics | grep -q 'node_'"
run_test "Nginx Exporter ë©”íŠ¸ë¦­" "curl -s http://localhost:${NGINX_EXPORTER_PORT}/metrics | grep -q 'nginx_'"
run_test "HAProxy ë©”íŠ¸ë¦­" "curl -s http://localhost:${HAPROXY_STATS_PORT}/metrics | grep -q 'haproxy_'"
run_test "Docker Stats ë©”íŠ¸ë¦­" "curl -s http://localhost:${DOCKER_STATS_PORT}/metrics | grep -q 'docker_'"

echo -e "\n${BLUE}4. Prometheus íƒ€ê²Ÿ ìƒíƒœ í™•ì¸${NC}"
run_test "Prometheus ìì²´ íƒ€ê²Ÿ" "curl -s http://localhost:${PROMETHEUS_PORT}/api/v1/targets | grep -q '\"health\":\"up\"'"

echo -e "\n${BLUE}5. í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸${NC}"
run_test "Auto-scaler í”„ë¡œì„¸ìŠ¤" "pgrep -f auto-scaler.sh > /dev/null"
run_test "Alert Webhook í”„ë¡œì„¸ìŠ¤" "pgrep -f alert-webhook.py > /dev/null"
run_test "Docker Stats Exporter í”„ë¡œì„¸ìŠ¤" "pgrep -f docker-stats-exporter.py > /dev/null"

echo -e "\n${BLUE}6. ë¡œë“œ ë°¸ëŸ°ì‹± í…ŒìŠ¤íŠ¸${NC}"
echo -e "${YELLOW}10ê°œ ìš”ì²­ì„ í†µí•œ ë¡œë“œ ë°¸ëŸ°ì‹± í™•ì¸...${NC}"
RESPONSES=""
for i in {1..10}; do
    RESPONSE=$(curl -s http://localhost:${HAPROXY_HTTP_PORT} | grep -o 'workspace-nginx-[0-9]*' | head -1 2>/dev/null || echo "")
    if [ -n "$RESPONSE" ]; then
        RESPONSES="${RESPONSES}${RESPONSE}\n"
    fi
done

if [ -n "$RESPONSES" ]; then
    UNIQUE_BACKENDS=$(echo -e "$RESPONSES" | sort -u | wc -l)
    if [ "$UNIQUE_BACKENDS" -gt 1 ]; then
        echo -e "${GREEN}âœ“ ë¡œë“œ ë°¸ëŸ°ì‹± ì‘ë™ í™•ì¸ (${UNIQUE_BACKENDS}ê°œ ë°±ì—”ë“œ ì‚¬ìš©)${NC}"
        ((TESTS_PASSED++))
    else
        echo -e "${YELLOW}âš  ë‹¨ì¼ ë°±ì—”ë“œë§Œ ì‘ë‹µ${NC}"
        ((TESTS_FAILED++))
    fi
else
    echo -e "${RED}âœ— ë¡œë“œ ë°¸ëŸ°ì‹± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨${NC}"
    ((TESTS_FAILED++))
fi

echo -e "\n${BLUE}================================================${NC}"
echo -e "${BLUE}                ìµœì¢… ê²°ê³¼${NC}"
echo -e "${BLUE}================================================${NC}"

echo -e "\n${GREEN}ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ:${NC}"
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

echo -e "\n${GREEN}ì„œë¹„ìŠ¤ ì ‘ì† ì •ë³´:${NC}"
echo "  - HAProxy Stats: http://localhost:${HAPROXY_HTTP_PORT}/haproxy-stats"
echo "  - Grafana: http://localhost:${GRAFANA_PORT} (admin/admin)"
echo "  - Prometheus: http://localhost:${PROMETHEUS_PORT}"
echo "  - AlertManager: http://localhost:${ALERTMANAGER_PORT}"

echo -e "\n${GREEN}ë¡œê·¸ í™•ì¸:${NC}"
echo "  - Auto-scaler: tail -f /var/log/auto-scaler.log"
echo "  - Alert Webhook: tail -f /var/log/alert-webhook.log"
echo "  - Docker Stats: tail -f /var/log/docker-stats-exporter.log"

echo -e "\n${BLUE}í…ŒìŠ¤íŠ¸ ê²°ê³¼:${NC}"
echo -e "${GREEN}í†µê³¼: ${TESTS_PASSED}ê°œ${NC}"
echo -e "${RED}ì‹¤íŒ¨: ${TESTS_FAILED}ê°œ${NC}"

if [ "$TESTS_FAILED" -eq 0 ]; then
    echo -e "\n${GREEN}ğŸ‰ ë°°í¬ ë° ê²€ì¦ ì™„ë£Œ! ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.${NC}"
    echo -e "\n${YELLOW}ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸:${NC}"
    echo "  docker exec -it workspace-nginx-1 stress --cpu 2 --timeout 30s"
    exit 0
else
    echo -e "\n${RED}âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.${NC}"
    echo -e "\n${YELLOW}ë””ë²„ê¹… ëª…ë ¹ì–´:${NC}"
    echo "  docker logs haproxy"
    echo "  docker logs prometheus"
    echo "  docker logs grafana"
    echo "  tail -f /var/log/auto-scaler.log"
    exit 1
fi